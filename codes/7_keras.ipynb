{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sps\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# alternative methods of loading keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras import regularizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve stored variables from preprocessing notebook\n",
    "\n",
    "%store -r Xlog_train_ss\n",
    "%store -r Xlog_val_ss\n",
    "%store -r Xlog_test_ss \n",
    "\n",
    "%store -r Xlog_train\n",
    "%store -r Xlog_val\n",
    "%store -r Xlog_test\n",
    "\n",
    "%store -r ylog_train\n",
    "%store -r ylog_val\n",
    "%store -r ylog_test \n",
    "\n",
    "%store -r X_train\n",
    "%store -r X_val\n",
    "%store -r X_test\n",
    "\n",
    "%store -r y_train\n",
    "%store -r y_val\n",
    "%store -r y_test\n",
    "\n",
    "%store -r X_train_ss\n",
    "%store -r X_val_ss\n",
    "%store -r X_test_ss\n",
    "\n",
    "%store -r X\n",
    "%store -r y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = Xlog_train.shape[1]\n",
    "input_shape = (n_cols, )\n",
    "\n",
    "# Creates a model given an activation and learning rate\n",
    "def create_model(learning_rate = 0.01, activation = 'relu'):\n",
    "  \n",
    "    # Create an Adam optimizer with the given learning rate\n",
    "    opt = Adam(lr=learning_rate)\n",
    "  \n",
    "    # Create a model with 2 hidden layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, \n",
    "                    activation = activation,\n",
    "                    input_shape = input_shape,\n",
    "                    activity_regularizer = regularizers.l2(1e-5)))\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(128,\n",
    "                    activation = activation, \n",
    "                    activity_regularizer = regularizers.l2(1e-5)))\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(1, activation = activation))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer = opt,\n",
    "                  loss = \"mse\",\n",
    "                  metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create a Keras Regressor\n",
    "model_1 = KerasRegressor(build_fn = create_model,\n",
    "                       verbose = 0)\n",
    "\n",
    "# Define the hyperparameter space\n",
    "params = {'batch_size': [16, 32], \n",
    "          'epochs': [100],\n",
    "          'learning_rate': [0.02, 0.01]}\n",
    "\n",
    "# Create a randomize search cv object \n",
    "random_search = RandomizedSearchCV(model_1,\n",
    "                                   param_distributions = params,\n",
    "                                   cv = KFold(10))\n",
    "random_search_results = random_search.fit(Xlog_train, ylog_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([669.52495759, 455.71868176, 239.12452421, 230.65378642]),\n",
       " 'std_fit_time': array([80.94071162, 89.76019963,  7.21527384, 11.27991699]),\n",
       " 'mean_score_time': array([0.94492939, 0.44517431, 0.26185436, 0.24453919]),\n",
       " 'std_score_time': array([0.17769696, 0.16413604, 0.03521401, 0.02159727]),\n",
       " 'param_learning_rate': masked_array(data=[0.02, 0.01, 0.02, 0.01],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[100, 100, 100, 100],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_batch_size': masked_array(data=[16, 16, 32, 32],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.02, 'epochs': 100, 'batch_size': 16},\n",
       "  {'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16},\n",
       "  {'learning_rate': 0.02, 'epochs': 100, 'batch_size': 32},\n",
       "  {'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32}],\n",
       " 'split0_test_score': array([-2.77537918e+00, -7.46664682e-07, -2.77537704e+00, -3.88533046e-08]),\n",
       " 'split1_test_score': array([-2.77536798e+00, -1.68654690e-08, -2.77536654e+00, -5.21271311e-08]),\n",
       " 'split2_test_score': array([-2.77536917e+00, -2.77536917e+00, -2.77536893e+00, -1.64358287e-08]),\n",
       " 'split3_test_score': array([-5.22877244e-08, -2.77538991e+00, -2.77538943e+00, -8.96049031e-08]),\n",
       " 'split4_test_score': array([-5.76131754e-07, -6.02066166e-08, -2.77538228e+00, -2.28113652e-08]),\n",
       " 'split5_test_score': array([-2.77537203e+00, -2.26393215e-08, -4.23165824e-04, -1.25464458e-05]),\n",
       " 'split6_test_score': array([-4.83584586e-07, -1.82163813e-08, -7.82281461e-07, -3.53841507e-08]),\n",
       " 'split7_test_score': array([-2.77537680e+00, -6.51056780e-07, -2.77537704e+00, -2.46673064e-08]),\n",
       " 'split8_test_score': array([-2.77537274e+00, -1.09830310e-07, -2.77537346e+00, -3.55975409e-08]),\n",
       " 'split9_test_score': array([-2.77538300e+00, -1.83756885e-08, -2.77538371e+00, -7.08205761e-08]),\n",
       " 'mean_test_score': array([-1.94276220e+00, -5.55076072e-01, -2.22034424e+00, -1.29327479e-06]),\n",
       " 'std_test_score': array([1.27183616e+00, 1.11015173e+00, 1.11006614e+00, 3.75111842e-06]),\n",
       " 'rank_test_score': array([3, 2, 4, 1])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE : 197724.3988144\n",
      "Val RMSE : 198126.0148006\n",
      "R2 Score : -0.8638293\n"
     ]
    }
   ],
   "source": [
    "log_train_pred = random_search.predict(Xlog_train)\n",
    "log_val_pred = random_search.predict(Xlog_val)\n",
    "\n",
    "train_pred = inv_boxcox(log_train_pred, -0.6)\n",
    "val_pred = inv_boxcox(log_val_pred, -0.6)\n",
    "\n",
    "# get the mean of results and square-root it to get RMSE\n",
    "print('Training RMSE : %.7f' % mean_squared_error(y_train, train_pred, squared=False))\n",
    "print('Val RMSE : %.7f' % mean_squared_error(y_val, val_pred, squared=False))\n",
    "print('R2 Score : %.7f' % r2_score(y_val,val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is really bad so I will try log transformed rather than boxcox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylog_train = np.log(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "# Select features to be considered for normalization (dummy variables are not included)\n",
    "numeric_cols = pd.Index(['floor_area_sqm', 'remaining_lease', 'floor_range',\n",
    "                 'pmi', 'cpi', 'gdp_growth','hdb_index','cli',\n",
    "                 'unemployed_rate', \n",
    "                 'dist_attraction', \n",
    "                  'dist_mrt', 'dist_mall', 'dist_market',\n",
    "                 'dist_park', 'dist_sport'])\n",
    "\n",
    "skewed_cols = Xlog_train[numeric_cols].apply(lambda x: skew(x.dropna())) \n",
    "skewed_cols = skewed_cols[skewed_cols > 0.7]\n",
    "skewed_cols = skewed_cols.index\n",
    "\n",
    "# Between -0.5 and 0.5 are considered sysmterical\n",
    "# Between -1 and -0.5 or between 0.5 and 1 are considered moderately skewed\n",
    "# Below -1 or above 1 is considered highly skewed\n",
    "# I decided to use 0.7 as the threshold to determine whether to apply normalization\n",
    "\n",
    "for s in skewed_cols:\n",
    "    Xlog_train[s] = np.log(X_train[s])\n",
    "    Xlog_val[s] = np.log(X_val[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x231b3eb2a08>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Keras Regressor\n",
    "model_2 = KerasRegressor(build_fn = create_model,\n",
    "                       verbose = 0)\n",
    "\n",
    "model_2.fit(x=Xlog_train, y=ylog_train, epochs=50, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE : 460654.8394156\n",
      "Val RMSE : 460302.3409795\n",
      "R2 Score : -9.1163112\n"
     ]
    }
   ],
   "source": [
    "log_train_pred = model_2.predict(Xlog_train)\n",
    "log_val_pred = model_2.predict(Xlog_val)\n",
    "\n",
    "train_pred = np.exp(log_train_pred)\n",
    "val_pred = np.exp(log_val_pred)\n",
    "\n",
    "# get the mean of results and square-root it to get RMSE\n",
    "print('Training RMSE : %.7f' % mean_squared_error(y_train, train_pred, squared=False))\n",
    "print('Val RMSE : %.7f' % mean_squared_error(y_val, val_pred, squared=False))\n",
    "print('R2 Score : %.7f' % r2_score(y_val,val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is still very bad, so will go without normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x231acfa0848>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Keras Regressor\n",
    "model_3 = KerasRegressor(build_fn = create_model,\n",
    "                       verbose = 0)\n",
    "\n",
    "model_3.fit(x=X_train, y=y_train, epochs=50, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE : 45412.3960336\n",
      "Val RMSE : 45589.5989104\n",
      "R2 Score : 0.9007644\n"
     ]
    }
   ],
   "source": [
    "train_pred = model_3.predict(X_train)\n",
    "val_pred = model_3.predict(X_val)\n",
    "\n",
    "# get the mean of results and square-root it to get RMSE\n",
    "print('Training RMSE : %.7f' % mean_squared_error(y_train, train_pred, squared=False))\n",
    "print('Val RMSE : %.7f' % mean_squared_error(y_val, val_pred, squared=False))\n",
    "print('R2 Score : %.7f' % r2_score(y_val,val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will use the above result for comparison with other XGBoost models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
